# 9 data engineer projects


| Name | Task description | Tools |
| :---------------------- | :---------------------- | :---------------------- |
| [01. User Segmentation. Datamarts](https://github.com/rombykoff/yandex-practicum-projects/tree/main/01.%20Исследование%20данных%20сервиса%20“Яндекс.Музыка”) | Create RFM segmentation in local DB | *`Docker`* *`PostgreSQL`* |
| [02. Online store. DB structure optimization](https://github.com/rombykoff/yandex-practicum-projects/tree/main/02.%20Исследование%20надежности%20заемщиков) | Re-build DB schema | *`Docker`* *`PostgreSQL`* |
| [03. Online store. ETL pipepline creation](https://github.com/rombykoff/yandex-practicum-projects/tree/main/03.%20Исследование%20объявлений%20о%20продаже%20квартир) | Change existing pipeline considering modifications in DB | *`Python`* *`Docker`* *`PostgreSQL`* *`Airflow`* |
| [04. Settlements with couriers. ETL pipepline creation](https://github.com/rombykoff/yandex-practicum-projects/tree/main/04.%20Определение%20выгодного%20тарифа%20для%20телеком%20компании) | Load data from external API to the local DB with Apache Airflow | *`Python`* *`Docker`* *`PostgreSQL`* *`MongoDB`* *`Airflow`* |
| [05. No project](https://github.com/rombykoff/yandex-practicum-projects/tree/main/05.%20Изучение%20закономерностей%2C%20определяющих%20успешность%20игр) |  |  |
| [06. Analytical datawarehouse. Data Vault](https://github.com/rombykoff/yandex-practicum-projects/tree/main/06.%20Анализ%20бизнес-показателей%20приложения%20Procrastinate%20Pro%2B) | Build an analytical storage based on Vertica using Data Vault storage model | *`Python`* *`Docker`*  *`Vertica`* *`Airflow`* |
| [07. Social network. Data Lake](https://github.com/rombykoff/yandex-practicum-projects/tree/main/07.%20Проверка%20гипотез%20для%20увеличения%20выручки%20интернет-магазина.%20А:В%20тесты.) | Create data marts on regular basis in Apache Hadoop file system | *`PySpark`* *`Hadoop`* *`Airflow`* |
| [08. Restaurant promotions. Real time data processing](https://github.com/rombykoff/yandex-practicum-projects/tree/main/08.%20Анализ%20поведения%20пользователей%20в%20приложении%20по%20продаже%20продуктов%20питания) | Receive messages from Kafka, process and send to two receivers: a Postgres database and a new topic for the Kafka broker | *`PySpark`* *`Kafka`* *`PostgreSQL`* |
| [09. Micro services. Cloud services](https://github.com/rombykoff/yandex-practicum-projects/tree/main/08.%20Анализ%20поведения%20пользователей%20в%20приложении%20по%20продаже%20продуктов%20питания) | Receive real-time data from the Kafka broker, process and decompose into different layers of the data warehouse | *`Kafka`* *`PostgreSQL`* *`Redis`* *`Kubernetes`* *`Python`* |
| [09. Final. Batch processing](https://github.com/rombykoff/yandex-practicum-projects/tree/main/08.%20Анализ%20поведения%20пользователей%20в%20приложении%20по%20продаже%20продуктов%20питания) | Create a pipeline, which retrieves data from Postgres for the given time period and uploads data extract to the Vertica | *`Vertica`* *`PostgreSQL`* *`Airflow`* *`Metabase`* *`Python`* |
